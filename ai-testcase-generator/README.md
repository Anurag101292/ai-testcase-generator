# ðŸ§  AI Test Case Generator (RAG) â€” Phase 1 & 2

This project is a **production-grade, modular, Retrieval-Augmented Generation (RAG)** system built using **Next.js + TypeScript** to automatically generate **test cases from Jira, Confluence, and GitHub** data.

### Currently Implemented:
- âœ… Mock data ingestion (Jira, Confluence, GitHub)
- âœ… Unified document layer
- âœ… Preprocessing & cleaning
- âœ… Token-aware chunking
- âœ… OpenAI embeddings (`text-embedding-3-large`)
- âœ… Local vector database
- âœ… Semantic retrieval (RAG foundation)

---

## ðŸŽ¯ Vision

The goal of this system is to:

> Automatically understand **requirements (Jira)**, **design (Confluence)**, and **code (GitHub)** and generate **accurate, grounded, and consistent test cases** using LLMs.

This is **not a toy chatbot**. It is a **real RAG-based engineering system**.

---

## ðŸ—ï¸ Architecture (Current)

```mermaid
graph TD
    Jira[Mock Jira] --> Ingestion
    Conf[Mock Confluence] --> Ingestion
    Git[Mock GitHub] --> Ingestion
    
    Ingestion --> Cleaning
    Cleaning --> Chunking
    Chunking --> Embedding
    Embedding --> VectorStore[Vector Store]
    
    UserQuery[User Query] --> EmbedQuery[Embed Query]
    EmbedQuery --> SimilaritySearch[Similarity Search]
    VectorStore --> SimilaritySearch
    SimilaritySearch --> Results[Relevant Knowledge Chunks]
```

*(Text-based representation)*
```
Mock Jira â”€â”  
Mock Conf â”€â”¼â”€> Ingestion â”€> Cleaning â”€> Chunking â”€> Embedding â”€> Vector Store  
Mock Git â”€â”€â”˜                                                    â†‘  
                                                                |  
User Query â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Embed Query â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Similarity Search  
                                                                |  
                                                                v  
                                                      Relevant Knowledge Chunks  
```

---

## ðŸ“ Project Structure

```bash
src/
â”œâ”€â”€ app/                  # Next.js UI
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ ingestion/        # Jira/Confluence/GitHub loaders (mock)
â”‚   â”œâ”€â”€ preprocessing/    # Cleaning & normalization
â”‚   â”œâ”€â”€ chunking/         # Chunk splitting
â”‚   â”œâ”€â”€ tokenization/     # Token counting
â”‚   â”œâ”€â”€ embedding/        # OpenAI embedding service
â”‚   â”œâ”€â”€ vectordb/         # Local vector store
â”‚   â”œâ”€â”€ orchestrator/     # RAG pipeline coordinator
â”‚   â””â”€â”€ types.ts          # Domain contracts
â”‚
â””â”€â”€ mockdata/
    â”œâ”€â”€ jira.json
    â”œâ”€â”€ confluence.json
    â””â”€â”€ github.json
```

---

## ðŸ”„ Data Flow

1. **Ingest**: Load mock Jira, Confluence, and GitHub data.
2. **Normalize**: Convert everything into a uniform `UnifiedDocument` structure.
3. **Clean**: text processing and normalization.
4. **Chunk**: Split content into manageable pieces.
5. **Token Count**: Calculate tokens for context window management.
6. **Embed**: Generate embeddings using OpenAI (`text-embedding-3-large`).
7. **Store**: persistent in local vector store.
8. **Retrieve**:
   - Embed user query.
   - Run cosine similarity search.
   - Return most relevant chunks.

---

## ðŸ§  Key Concepts Implemented

- **RAG Foundation**: Retrieval Augmented Generation architecture.
- **Semantic Search**: Using vector embeddings for meaning-based lookups.
- **Token-aware Chunking**: optimizing for LLM context limits.
- **Enterprise Architecture**: Separation of concerns and modular design.
- **Unified Knowledge Layer**: Source-agnostic document handling.

---

## ðŸ”‘ Environment Setup

1. Create a `.env.local` file in the root directory (or `.env`).
2. Add your OpenAI API Key:

```bash
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxx
```

---

## â–¶ï¸ How to Run

1. **Install Dependencies**:
   ```bash
   npm install
   ```

2. **Run Development Server**:
   ```bash
   npm run dev
   ```

3. **Open Application**:
   Navigate to [http://localhost:3000](http://localhost:3000).

   You should see retrieved chunks for a test query like:
   > "login password rules"

---

## ðŸ§ª Status

The following core components are currently verified and operational:
- [x] Ingestion
- [x] Chunking
- [x] Embedding
- [x] Vector Search
- [x] Retrieval Quality
